{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 3\n",
      "Class names: ['healthy', 'red_spider_mite', 'Rust']\n",
      "Training dataset:\n",
      "  Image shape: (32, 224, 224, 3)\n",
      "  Label shape: (32,)\n",
      "  Types: <dtype: 'float64'>, <dtype: 'int32'>\n",
      "  Min-Max pixel values: 0.00, 1.00\n",
      "Validation dataset:\n",
      "  Image shape: (32, 224, 224, 3)\n",
      "  Label shape: (32,)\n",
      "  Types: <dtype: 'float64'>, <dtype: 'int32'>\n",
      "  Min-Max pixel values: 0.00, 1.00\n",
      "Test dataset:\n",
      "  Image shape: (32, 224, 224, 3)\n",
      "  Label shape: (32,)\n",
      "  Types: <dtype: 'float64'>, <dtype: 'int32'>\n",
      "  Min-Max pixel values: 0.00, 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_and_preprocess_data(data_dir, img_size=(224, 224), batch_size=32):\n",
    "    # Define class names based on your dataset structure\n",
    "    class_names = ['healthy', 'red_spider_mite', 'Rust']\n",
    "\n",
    "    # Load and preprocess images\n",
    "    train_images, train_labels = [], []\n",
    "    test_images, test_labels = [], []\n",
    "\n",
    "    for split in ['Train', 'test']:\n",
    "        for class_idx, class_name in enumerate(class_names):\n",
    "            if split == 'Train':\n",
    "                class_dir = os.path.join(data_dir, split, class_name.replace('_', ' '))\n",
    "            else:\n",
    "                class_dir = os.path.join(data_dir, split, class_name)\n",
    "            \n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"Warning: Directory not found: {class_dir}\")\n",
    "                continue\n",
    "            \n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = img.resize(img_size)\n",
    "                img_array = np.array(img) / 255.0  # Normalize pixel values\n",
    "                if split == 'Train':\n",
    "                    train_images.append(img_array)\n",
    "                    train_labels.append(class_idx)\n",
    "                else:\n",
    "                    test_images.append(img_array)\n",
    "                    test_labels.append(class_idx)\n",
    "\n",
    "    train_images, train_labels = np.array(train_images), np.array(train_labels)\n",
    "    test_images, test_labels = np.array(test_images), np.array(test_labels)\n",
    "\n",
    "    # Split training data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, stratify=train_labels, random_state=42)\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(1000).batch(batch_size)\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)\n",
    "\n",
    "    return train_ds, val_ds, test_ds, class_names\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = r\"C:/Users/91911/OneDrive/Desktop/IEEE/COFFEE/dataset\"\n",
    "    train_ds, val_ds, test_ds, class_names = load_and_preprocess_data(data_dir)\n",
    "    \n",
    "    print(f\"Number of classes: {len(class_names)}\")\n",
    "    print(f\"Class names: {class_names}\")\n",
    "    \n",
    "    # Print information about the datasets\n",
    "    for dataset, name in zip([train_ds, val_ds, test_ds], [\"Training\", \"Validation\", \"Test\"]):\n",
    "        images, labels = next(iter(dataset))\n",
    "        print(f\"{name} dataset:\")\n",
    "        print(f\"  Image shape: {images.shape}\")\n",
    "        print(f\"  Label shape: {labels.shape}\")\n",
    "        print(f\"  Types: {images.dtype}, {labels.dtype}\")\n",
    "        print(f\"  Min-Max pixel values: {tf.reduce_min(images).numpy():.2f}, {tf.reduce_max(images).numpy():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 594ms/step - accuracy: 0.3933 - loss: 3.2412 - val_accuracy: 0.4071 - val_loss: 1.0496\n",
      "Epoch 2/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.4263 - loss: 1.0683 - val_accuracy: 0.4071 - val_loss: 1.0399\n",
      "Epoch 3/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.3881 - loss: 1.0607 - val_accuracy: 0.3643 - val_loss: 1.0335\n",
      "Epoch 4/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.4152 - loss: 1.0802 - val_accuracy: 0.4000 - val_loss: 1.0150\n",
      "Epoch 5/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.3901 - loss: 1.0344 - val_accuracy: 0.4286 - val_loss: 1.0433\n",
      "Epoch 6/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 530ms/step - accuracy: 0.3897 - loss: 1.0479 - val_accuracy: 0.4000 - val_loss: 1.0306\n",
      "Epoch 7/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.4301 - loss: 1.0323 - val_accuracy: 0.3857 - val_loss: 1.0296\n",
      "Epoch 8/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.4543 - loss: 1.0319 - val_accuracy: 0.3714 - val_loss: 1.0118\n",
      "Epoch 9/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.4512 - loss: 1.0026 - val_accuracy: 0.4429 - val_loss: 1.0100\n",
      "Epoch 10/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 497ms/step - accuracy: 0.4541 - loss: 0.9802 - val_accuracy: 0.4714 - val_loss: 0.9942\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.6476 - loss: 0.9364\n",
      "Test accuracy: 0.4500\n",
      "CNN Model Test Accuracy: 0.4500\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "\n",
    "def create_cnn_model(input_shape=(224, 224, 3), num_classes=3):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def apply_traditional_augmentations(ds):\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.2),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ])\n",
    "    return ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
    "                  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "def train_and_evaluate_model(model, train_ds, val_ds, test_ds, epochs=10):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return history, test_acc\n",
    "\n",
    "# Load the data (assuming you've already run the data preparation script)\n",
    "data_dir = r\"C:/Users/91911/OneDrive/Desktop/IEEE/COFFEE/dataset\"\n",
    "train_ds, val_ds, test_ds, class_names = load_and_preprocess_data(data_dir)\n",
    "\n",
    "# Apply traditional augmentations to the training data\n",
    "augmented_train_ds = apply_traditional_augmentations(train_ds)\n",
    "\n",
    "# Create and train the CNN model\n",
    "cnn_model = create_cnn_model()\n",
    "cnn_history, cnn_test_acc = train_and_evaluate_model(cnn_model, augmented_train_ds, val_ds, test_ds)\n",
    "\n",
    "print(f\"CNN Model Test Accuracy: {cnn_test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model saved as 'cnn_coffee_leaf_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# Save the trained CNN model\n",
    "cnn_model.save('cnn_coffee_leaf_model.h5')\n",
    "print(\"CNN model saved as 'cnn_coffee_leaf_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91911\\AppData\\Local\\Temp\\ipykernel_7292\\844133934.py:66: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  \"MobileNetV2\": create_transfer_learning_model(MobileNetV2(weights='imagenet', include_top=False)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "\n",
      "Training ResNet50 with traditional augmentation:\n",
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 11s/step - accuracy: 0.3331 - loss: 1.1561 - val_accuracy: 0.4000 - val_loss: 1.0945 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 13s/step - accuracy: 0.3703 - loss: 1.1617 - val_accuracy: 0.4071 - val_loss: 1.0232 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 14s/step - accuracy: 0.4155 - loss: 1.0643 - val_accuracy: 0.4000 - val_loss: 1.0051 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 18s/step - accuracy: 0.3793 - loss: 1.0691 - val_accuracy: 0.4071 - val_loss: 1.0062 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 15s/step - accuracy: 0.3952 - loss: 1.0724 - val_accuracy: 0.4071 - val_loss: 0.9844 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4264 - loss: 1.0601 - val_accuracy: 0.3929 - val_loss: 1.0024 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.4098 - loss: 1.0428 - val_accuracy: 0.4857 - val_loss: 0.9875 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.4689 - loss: 1.0265 - val_accuracy: 0.4643 - val_loss: 0.9809 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.4404 - loss: 1.0280 - val_accuracy: 0.5071 - val_loss: 0.9974 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.4329 - loss: 1.0413 - val_accuracy: 0.4429 - val_loss: 0.9588 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.4194 - loss: 1.0631 - val_accuracy: 0.4500 - val_loss: 0.9736 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.4482 - loss: 1.0727 - val_accuracy: 0.4786 - val_loss: 1.0288 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3s/step - accuracy: 0.3999 - loss: 1.0670 - val_accuracy: 0.4643 - val_loss: 0.9991 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 0.4157 - loss: 1.0312 - val_accuracy: 0.5000 - val_loss: 0.9661 - learning_rate: 2.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 9s/step - accuracy: 0.4412 - loss: 1.0442 - val_accuracy: 0.5286 - val_loss: 0.9636 - learning_rate: 2.0000e-04\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 11s/step - accuracy: 0.2736 - loss: 0.9822\n",
      "Test accuracy: 0.4233\n",
      "\n",
      "Training ResNet50 with MixUp augmentation:\n",
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 17s/step - accuracy: 0.4100 - loss: 1.0833 - val_accuracy: 0.4500 - val_loss: 1.1465 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 5s/step - accuracy: 0.4294 - loss: 1.1051 - val_accuracy: 0.4429 - val_loss: 0.9761 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.4315 - loss: 1.0409 - val_accuracy: 0.5000 - val_loss: 0.9815 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.3931 - loss: 1.0334 - val_accuracy: 0.4643 - val_loss: 0.9984 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.4018 - loss: 1.0313 - val_accuracy: 0.5214 - val_loss: 0.9726 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3s/step - accuracy: 0.4788 - loss: 1.0181 - val_accuracy: 0.4571 - val_loss: 0.9809 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.4042 - loss: 1.0736 - val_accuracy: 0.5500 - val_loss: 0.9841 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 0.3462 - loss: 1.0868 - val_accuracy: 0.4714 - val_loss: 0.9949 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3s/step - accuracy: 0.4394 - loss: 1.0364 - val_accuracy: 0.4786 - val_loss: 0.9670 - learning_rate: 2.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.4485 - loss: 1.0260 - val_accuracy: 0.4929 - val_loss: 0.9683 - learning_rate: 2.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - accuracy: 0.4585 - loss: 1.0235 - val_accuracy: 0.4929 - val_loss: 0.9669 - learning_rate: 2.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3s/step - accuracy: 0.4129 - loss: 1.0174 - val_accuracy: 0.5000 - val_loss: 0.9643 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.4408 - loss: 1.0441 - val_accuracy: 0.5143 - val_loss: 0.9617 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 0.3932 - loss: 1.0423 - val_accuracy: 0.5071 - val_loss: 0.9589 - learning_rate: 2.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.4268 - loss: 1.0141 - val_accuracy: 0.5357 - val_loss: 0.9693 - learning_rate: 2.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.4501 - loss: 1.0332 - val_accuracy: 0.5214 - val_loss: 0.9570 - learning_rate: 2.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.4487 - loss: 1.0307 - val_accuracy: 0.5286 - val_loss: 0.9633 - learning_rate: 2.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.4681 - loss: 1.0197 - val_accuracy: 0.4857 - val_loss: 0.9639 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.4328 - loss: 1.0171 - val_accuracy: 0.5357 - val_loss: 0.9640 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.4718 - loss: 1.0031 - val_accuracy: 0.5000 - val_loss: 0.9645 - learning_rate: 4.0000e-05\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.5395 - loss: 0.9356\n",
      "Test accuracy: 0.5200\n",
      "\n",
      "Training MobileNetV2 with traditional augmentation:\n",
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 604ms/step - accuracy: 0.4620 - loss: 1.1847 - val_accuracy: 0.6857 - val_loss: 0.7738 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 527ms/step - accuracy: 0.6747 - loss: 0.7361 - val_accuracy: 0.6786 - val_loss: 0.7792 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 533ms/step - accuracy: 0.7181 - loss: 0.6606 - val_accuracy: 0.7000 - val_loss: 0.6937 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 520ms/step - accuracy: 0.7124 - loss: 0.7058 - val_accuracy: 0.6857 - val_loss: 0.7716 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 622ms/step - accuracy: 0.7174 - loss: 0.5909 - val_accuracy: 0.7357 - val_loss: 0.6625 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 624ms/step - accuracy: 0.7456 - loss: 0.5774 - val_accuracy: 0.6929 - val_loss: 0.7237 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 664ms/step - accuracy: 0.7732 - loss: 0.5843 - val_accuracy: 0.7214 - val_loss: 0.6458 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 701ms/step - accuracy: 0.8128 - loss: 0.4903 - val_accuracy: 0.6929 - val_loss: 0.7461 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 562ms/step - accuracy: 0.7966 - loss: 0.4794 - val_accuracy: 0.7000 - val_loss: 0.6865 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 581ms/step - accuracy: 0.8257 - loss: 0.4567 - val_accuracy: 0.6929 - val_loss: 0.7106 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 580ms/step - accuracy: 0.8323 - loss: 0.4407 - val_accuracy: 0.7429 - val_loss: 0.6287 - learning_rate: 2.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 670ms/step - accuracy: 0.8353 - loss: 0.4654 - val_accuracy: 0.7214 - val_loss: 0.6610 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 671ms/step - accuracy: 0.8301 - loss: 0.4508 - val_accuracy: 0.7357 - val_loss: 0.6490 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 595ms/step - accuracy: 0.8642 - loss: 0.4166 - val_accuracy: 0.7000 - val_loss: 0.6549 - learning_rate: 2.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 582ms/step - accuracy: 0.8547 - loss: 0.4233 - val_accuracy: 0.7143 - val_loss: 0.6374 - learning_rate: 4.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 800ms/step - accuracy: 0.8431 - loss: 0.4123 - val_accuracy: 0.7143 - val_loss: 0.6458 - learning_rate: 4.0000e-05\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 601ms/step - accuracy: 0.7345 - loss: 0.7455\n",
      "Test accuracy: 0.6233\n",
      "\n",
      "Training MobileNetV2 with MixUp augmentation:\n",
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 809ms/step - accuracy: 0.8046 - loss: 0.5906 - val_accuracy: 0.7357 - val_loss: 0.6588 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 711ms/step - accuracy: 0.7877 - loss: 0.5381 - val_accuracy: 0.7286 - val_loss: 0.6924 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 692ms/step - accuracy: 0.8264 - loss: 0.5098 - val_accuracy: 0.6643 - val_loss: 0.7261 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 682ms/step - accuracy: 0.8399 - loss: 0.4871 - val_accuracy: 0.7571 - val_loss: 0.5895 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 697ms/step - accuracy: 0.8284 - loss: 0.4718 - val_accuracy: 0.7786 - val_loss: 0.5461 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 688ms/step - accuracy: 0.7928 - loss: 0.5802 - val_accuracy: 0.7286 - val_loss: 0.6952 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 684ms/step - accuracy: 0.7963 - loss: 0.5489 - val_accuracy: 0.7643 - val_loss: 0.6058 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 643ms/step - accuracy: 0.8264 - loss: 0.4898 - val_accuracy: 0.7143 - val_loss: 0.7420 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 700ms/step - accuracy: 0.8461 - loss: 0.4597 - val_accuracy: 0.7500 - val_loss: 0.6445 - learning_rate: 2.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 680ms/step - accuracy: 0.8643 - loss: 0.4428 - val_accuracy: 0.7214 - val_loss: 0.6742 - learning_rate: 2.0000e-04\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 492ms/step - accuracy: 0.7842 - loss: 0.6177\n",
      "Test accuracy: 0.6533\n",
      "\n",
      "Training EfficientNetB0 with traditional augmentation:\n",
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.3768 - loss: 1.0768 - val_accuracy: 0.4000 - val_loss: 1.0450 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.4346 - loss: 1.0522 - val_accuracy: 0.4071 - val_loss: 1.0508 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.4048 - loss: 1.0550 - val_accuracy: 0.4000 - val_loss: 1.0432 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.4139 - loss: 1.0556 - val_accuracy: 0.4071 - val_loss: 1.0415 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.4184 - loss: 1.0593 - val_accuracy: 0.4071 - val_loss: 1.0410 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.4065 - loss: 1.0515 - val_accuracy: 0.4000 - val_loss: 1.0406 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.3735 - loss: 1.0523 - val_accuracy: 0.4000 - val_loss: 1.0405 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3920 - loss: 1.0578 - val_accuracy: 0.4000 - val_loss: 1.0396 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.4221 - loss: 1.0587 - val_accuracy: 0.4071 - val_loss: 1.0409 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 999ms/step - accuracy: 0.4249 - loss: 1.0712 - val_accuracy: 0.4000 - val_loss: 1.0437 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 772ms/step - accuracy: 0.4325 - loss: 1.0302 - val_accuracy: 0.4071 - val_loss: 1.0432 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 669ms/step - accuracy: 0.4127 - loss: 1.0593 - val_accuracy: 0.4071 - val_loss: 1.0443 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 675ms/step - accuracy: 0.4346 - loss: 1.0297 - val_accuracy: 0.4071 - val_loss: 1.0408 - learning_rate: 2.0000e-04\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 735ms/step - accuracy: 0.1487 - loss: 0.9586\n",
      "Test accuracy: 0.3867\n",
      "\n",
      "Training EfficientNetB0 with MixUp augmentation:\n",
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.4099 - loss: 1.0706 - val_accuracy: 0.4071 - val_loss: 1.0490 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.4335 - loss: 1.0381 - val_accuracy: 0.4000 - val_loss: 1.0428 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3765 - loss: 1.0719 - val_accuracy: 0.4000 - val_loss: 1.0393 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.4092 - loss: 1.0542 - val_accuracy: 0.4071 - val_loss: 1.0412 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3982 - loss: 1.0547 - val_accuracy: 0.4000 - val_loss: 1.0415 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3620 - loss: 1.0671 - val_accuracy: 0.4071 - val_loss: 1.0392 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3599 - loss: 1.0548 - val_accuracy: 0.4071 - val_loss: 1.0395 - learning_rate: 2.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3729 - loss: 1.0567 - val_accuracy: 0.4071 - val_loss: 1.0401 - learning_rate: 2.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.3962 - loss: 1.0520 - val_accuracy: 0.4000 - val_loss: 1.0403 - learning_rate: 2.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3913 - loss: 1.0424 - val_accuracy: 0.4000 - val_loss: 1.0401 - learning_rate: 4.0000e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 895ms/step - accuracy: 0.4162 - loss: 1.0527 - val_accuracy: 0.4071 - val_loss: 1.0401 - learning_rate: 4.0000e-05\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 585ms/step - accuracy: 0.7805 - loss: 0.9464\n",
      "Test accuracy: 0.5100\n",
      "\n",
      "Final Results:\n",
      "ResNet50_traditional: 0.4233\n",
      "ResNet50_mixup: 0.5200\n",
      "MobileNetV2_traditional: 0.6233\n",
      "MobileNetV2_mixup: 0.6533\n",
      "EfficientNetB0_traditional: 0.3867\n",
      "EfficientNetB0_mixup: 0.5100\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "import numpy as np\n",
    "\n",
    "def create_transfer_learning_model(base_model, num_classes=3):\n",
    "    base_model.trainable = False\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    index = tf.random.shuffle(tf.range(batch_size))\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * tf.gather(x, index)\n",
    "    mixed_y = lam * y + (1 - lam) * tf.gather(y, index)\n",
    "    return mixed_x, mixed_y\n",
    "\n",
    "def train_and_evaluate_model(model, train_ds, val_ds, test_ds, epochs=20, use_mixup=False):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=3)\n",
    "    ]\n",
    "    \n",
    "    if use_mixup:\n",
    "        train_ds = train_ds.map(lambda x, y: mixup_data(x, tf.one_hot(y, depth=3)))\n",
    "    else:\n",
    "        train_ds = train_ds.map(lambda x, y: (x, tf.one_hot(y, depth=3)))\n",
    "    \n",
    "    val_ds = val_ds.map(lambda x, y: (x, tf.one_hot(y, depth=3)))\n",
    "    test_ds = test_ds.map(lambda x, y: (x, tf.one_hot(y, depth=3)))\n",
    "    \n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return history, test_acc\n",
    "\n",
    "# Load the data (assuming you've already run the data preparation script)\n",
    "data_dir = r\"C:/Users/91911/OneDrive/Desktop/IEEE/COFFEE/dataset\"\n",
    "train_ds, val_ds, test_ds, class_names = load_and_preprocess_data(data_dir)\n",
    "\n",
    "# Apply traditional augmentations to the training data\n",
    "augmented_train_ds = apply_traditional_augmentations(train_ds)\n",
    "\n",
    "# Create and train the advanced models\n",
    "models = {\n",
    "    \"ResNet50\": create_transfer_learning_model(ResNet50(weights='imagenet', include_top=False)),\n",
    "    \"MobileNetV2\": create_transfer_learning_model(MobileNetV2(weights='imagenet', include_top=False)),\n",
    "    \"EfficientNetB0\": create_transfer_learning_model(EfficientNetB0(weights='imagenet', include_top=False))\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name} with traditional augmentation:\")\n",
    "    _, acc = train_and_evaluate_model(model, augmented_train_ds, val_ds, test_ds)\n",
    "    results[f\"{model_name}_traditional\"] = acc\n",
    "    \n",
    "    print(f\"\\nTraining {model_name} with MixUp augmentation:\")\n",
    "    _, acc = train_and_evaluate_model(model, augmented_train_ds, val_ds, test_ds, use_mixup=True)\n",
    "    results[f\"{model_name}_mixup\"] = acc\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "for model_name, acc in results.items():\n",
    "    print(f\"{model_name}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model\n",
    "best_model_key = max(results, key=results.get)\n",
    "best_model_name = best_model_key.split('_')[0]\n",
    "best_model = models[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model 'MobileNetV2' \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"The best model '{best_model_name}' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning MobileNetV2:\n",
      "Epoch 1/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3s/step - accuracy: 0.4153 - loss: 1.2498 - val_accuracy: 0.4429 - val_loss: 1.1738 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.5731 - loss: 1.0628 - val_accuracy: 0.4786 - val_loss: 1.2149 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.6241 - loss: 0.9020 - val_accuracy: 0.4571 - val_loss: 1.4645 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.6812 - loss: 0.8750 - val_accuracy: 0.4571 - val_loss: 1.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.7171 - loss: 0.8350 - val_accuracy: 0.4286 - val_loss: 1.6974 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.7397 - loss: 0.8176 - val_accuracy: 0.4214 - val_loss: 2.0845 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.7424 - loss: 0.7945 - val_accuracy: 0.4214 - val_loss: 1.9720 - learning_rate: 2.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.7544 - loss: 0.8010 - val_accuracy: 0.4286 - val_loss: 1.8776 - learning_rate: 2.0000e-05\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 478ms/step - accuracy: 0.7874 - loss: 0.5967\n",
      "Test accuracy: 0.5367\n",
      "\n",
      "Training ensemble model 1:\n",
      "Epoch 1/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3s/step - accuracy: 0.3864 - loss: 1.2931 - val_accuracy: 0.4071 - val_loss: 1.6982 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.5991 - loss: 0.9032 - val_accuracy: 0.4071 - val_loss: 2.2223 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.6728 - loss: 0.7523 - val_accuracy: 0.4071 - val_loss: 3.1441 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.7247 - loss: 0.6491 - val_accuracy: 0.4071 - val_loss: 3.7235 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.7663 - loss: 0.5727 - val_accuracy: 0.4071 - val_loss: 3.8349 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.8185 - loss: 0.4580 - val_accuracy: 0.4143 - val_loss: 4.2271 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.8432 - loss: 0.4417 - val_accuracy: 0.4143 - val_loss: 4.1701 - learning_rate: 2.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.8404 - loss: 0.4573 - val_accuracy: 0.4143 - val_loss: 3.9658 - learning_rate: 2.0000e-05\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 509ms/step - accuracy: 0.7805 - loss: 0.7015\n",
      "Test accuracy: 0.5100\n",
      "\n",
      "Training ensemble model 2:\n",
      "Epoch 1/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 3s/step - accuracy: 0.4152 - loss: 1.2763 - val_accuracy: 0.4286 - val_loss: 1.3931 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.6387 - loss: 0.8545 - val_accuracy: 0.4143 - val_loss: 1.9359 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.7325 - loss: 0.6907 - val_accuracy: 0.4071 - val_loss: 2.9120 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.7395 - loss: 0.6180 - val_accuracy: 0.4071 - val_loss: 3.4346 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.7816 - loss: 0.5570 - val_accuracy: 0.4214 - val_loss: 3.2392 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 0.8182 - loss: 0.4576 - val_accuracy: 0.4500 - val_loss: 2.7540 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.8399 - loss: 0.3892 - val_accuracy: 0.4357 - val_loss: 2.8553 - learning_rate: 2.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3s/step - accuracy: 0.8523 - loss: 0.3919 - val_accuracy: 0.4357 - val_loss: 2.9693 - learning_rate: 2.0000e-05\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 534ms/step - accuracy: 0.8022 - loss: 0.6016\n",
      "Test accuracy: 0.5500\n",
      "\n",
      "Training ensemble model 3:\n",
      "Epoch 1/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3s/step - accuracy: 0.3730 - loss: 1.3221 - val_accuracy: 0.4286 - val_loss: 1.0782 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.5324 - loss: 1.0241 - val_accuracy: 0.4429 - val_loss: 1.2143 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.6307 - loss: 0.9049 - val_accuracy: 0.4357 - val_loss: 1.4461 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 0.7055 - loss: 0.8210 - val_accuracy: 0.4571 - val_loss: 1.5727 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.7736 - loss: 0.7288 - val_accuracy: 0.4714 - val_loss: 1.8686 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.7868 - loss: 0.6994 - val_accuracy: 0.4714 - val_loss: 2.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.7782 - loss: 0.6835 - val_accuracy: 0.4714 - val_loss: 1.8740 - learning_rate: 2.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.8004 - loss: 0.6637 - val_accuracy: 0.4786 - val_loss: 1.8342 - learning_rate: 2.0000e-05\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 455ms/step - accuracy: 0.7682 - loss: 0.7077\n",
      "Test accuracy: 0.5500\n",
      "\n",
      "Evaluating ensemble model:\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.7916 - loss: 0.5998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "Fine-tuned MobileNetV2: 0.5367\n",
      "Ensemble Model: 0.5300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to synchronously create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[0;32m     82\u001b[0m best_model \u001b[38;5;241m=\u001b[39m fine_tuned_model \u001b[38;5;28;01mif\u001b[39;00m fine_tuned_acc \u001b[38;5;241m>\u001b[39m ensemble_acc \u001b[38;5;28;01melse\u001b[39;00m ensemble_model\n\u001b[1;32m---> 83\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_coffee_leaf_modelww.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest model saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_coffee_leaf_modelww.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\h5py\\_hl\\group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\h5py\\_hl\\dataset.py:163\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[1;32m--> 163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m    166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5d.pyx:137\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to synchronously create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "import numpy as np\n",
    "\n",
    "def create_fine_tuned_model(num_classes=3):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Unfreeze the last few layers\n",
    "    for layer in base_model.layers[-20:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_model(model, train_ds, val_ds, test_ds, epochs=30, use_mixup=True):\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=5)\n",
    "    ]\n",
    "    \n",
    "    if use_mixup:\n",
    "        train_ds = train_ds.map(lambda x, y: mixup_data(x, tf.one_hot(y, depth=3)))\n",
    "    else:\n",
    "        train_ds = train_ds.map(lambda x, y: (x, tf.one_hot(y, depth=3)))\n",
    "    \n",
    "    val_ds = val_ds.map(lambda x, y: (x, tf.one_hot(y, depth=3)))\n",
    "    test_ds = test_ds.map(lambda x, y: (x, tf.one_hot(y, depth=3)))\n",
    "    \n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return history, test_acc\n",
    "\n",
    "def create_ensemble(models):\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    outputs = [model(inputs) for model in models]\n",
    "    ensemble_output = layers.Average()(outputs)\n",
    "    ensemble_model = tf.keras.Model(inputs=inputs, outputs=ensemble_output)\n",
    "    return ensemble_model\n",
    "\n",
    "# Load the data and apply augmentations (assuming you've already defined these functions)\n",
    "data_dir = r\"C:/Users/91911/OneDrive/Desktop/IEEE/COFFEE/dataset\"\n",
    "train_ds, val_ds, test_ds, class_names = load_and_preprocess_data(data_dir)\n",
    "augmented_train_ds = apply_traditional_augmentations(train_ds)\n",
    "\n",
    "# Fine-tune MobileNetV2\n",
    "fine_tuned_model = create_fine_tuned_model()\n",
    "print(\"\\nFine-tuning MobileNetV2:\")\n",
    "_, fine_tuned_acc = train_and_evaluate_model(fine_tuned_model, augmented_train_ds, val_ds, test_ds)\n",
    "\n",
    "# Create and train multiple models for ensemble\n",
    "ensemble_models = [create_fine_tuned_model() for _ in range(3)]\n",
    "for i, model in enumerate(ensemble_models):\n",
    "    print(f\"\\nTraining ensemble model {i+1}:\")\n",
    "    train_and_evaluate_model(model, augmented_train_ds, val_ds, test_ds)\n",
    "\n",
    "# Create and evaluate ensemble\n",
    "ensemble_model = create_ensemble(ensemble_models)\n",
    "print(\"\\nEvaluating ensemble model:\")\n",
    "ensemble_model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "_, ensemble_acc = ensemble_model.evaluate(test_ds.map(lambda x, y: (x, tf.one_hot(y, depth=3))))\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Fine-tuned MobileNetV2: {fine_tuned_acc:.4f}\")\n",
    "print(f\"Ensemble Model: {ensemble_acc:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "best_model = fine_tuned_model if fine_tuned_acc > ensemble_acc else ensemble_model\n",
    "best_model.save('best_coffee_leaf_modelww.h5')\n",
    "print(f\"\\nBest model saved as 'best_coffee_leaf_modelww.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 2 classes.\n",
      "Using 800 files for training.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Using 200 files for validation.\n",
      "\n",
      "Training advanced model:\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.4223 - loss: 1.2336 - val_accuracy: 0.6250 - val_loss: 0.8037 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.5885 - loss: 0.8564 - val_accuracy: 0.5750 - val_loss: 0.7314 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 3s/step - accuracy: 0.6124 - loss: 0.7779 - val_accuracy: 0.7000 - val_loss: 0.5401 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 3s/step - accuracy: 0.7074 - loss: 0.6524 - val_accuracy: 0.8000 - val_loss: 0.4722 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.7413 - loss: 0.5842 - val_accuracy: 0.7750 - val_loss: 0.4189 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.7757 - loss: 0.5893 - val_accuracy: 0.7500 - val_loss: 0.5031 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.7900 - loss: 0.5188 - val_accuracy: 0.5500 - val_loss: 0.9688 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.7775 - loss: 0.5641 - val_accuracy: 0.8500 - val_loss: 0.3466 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.7979 - loss: 0.5884 - val_accuracy: 0.8000 - val_loss: 0.5363 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.8101 - loss: 0.5469 - val_accuracy: 0.7500 - val_loss: 1.0165 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.8626 - loss: 0.4112 - val_accuracy: 0.7750 - val_loss: 0.5419 - learning_rate: 9.0484e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.8728 - loss: 0.4043 - val_accuracy: 0.7750 - val_loss: 0.7134 - learning_rate: 8.1873e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.8966 - loss: 0.4324 - val_accuracy: 0.8250 - val_loss: 0.5004 - learning_rate: 1.4816e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.8984 - loss: 0.4089 - val_accuracy: 0.8250 - val_loss: 0.4573 - learning_rate: 1.3406e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8906 - loss: 0.3484 - val_accuracy: 0.9250 - val_loss: 0.2617 - learning_rate: 1.2131e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9053 - loss: 0.4435 - val_accuracy: 0.8250 - val_loss: 0.3911 - learning_rate: 1.0976e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9189 - loss: 0.3326 - val_accuracy: 0.8750 - val_loss: 0.2003 - learning_rate: 9.9317e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9166 - loss: 0.3580 - val_accuracy: 0.8250 - val_loss: 0.3411 - learning_rate: 8.9866e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.9108 - loss: 0.3990 - val_accuracy: 0.8000 - val_loss: 0.6327 - learning_rate: 8.1314e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.8925 - loss: 0.4049 - val_accuracy: 0.8000 - val_loss: 0.3651 - learning_rate: 7.3576e-06\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.9176 - loss: 0.3899 - val_accuracy: 0.8750 - val_loss: 0.2179 - learning_rate: 6.6574e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9084 - loss: 0.3923 - val_accuracy: 0.8750 - val_loss: 0.4146 - learning_rate: 1.2048e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.9171 - loss: 0.3669 - val_accuracy: 0.8000 - val_loss: 0.4771 - learning_rate: 1.0901e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.9116 - loss: 0.3774 - val_accuracy: 0.8500 - val_loss: 0.3589 - learning_rate: 9.8639e-07\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.9188 - loss: 0.3996 - val_accuracy: 0.7250 - val_loss: 0.6087 - learning_rate: 8.9252e-07\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9371 - loss: 0.3278 - val_accuracy: 0.8750 - val_loss: 0.2213 - learning_rate: 8.0759e-07\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.8889 - loss: 0.3785 - val_accuracy: 0.9000 - val_loss: 0.2652 - learning_rate: 1.4615e-07\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 443ms/step - accuracy: 0.8295 - loss: 0.4066\n",
      "Test accuracy: 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Advanced Model Accuracy: 0.8375\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to synchronously create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 153\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAdvanced Model Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madvanced_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m \u001b[43madvanced_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_coffee_leaf_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest model saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_coffee_leaf_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining history plot saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_history.png\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\h5py\\_hl\\group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\h5py\\_hl\\dataset.py:163\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[1;32m--> 163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m    166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5d.pyx:137\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to synchronously create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50, EfficientNetB0\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_and_preprocess_data(data_dir):\n",
    "    img_size = (224, 224)\n",
    "    batch_size = 32\n",
    "\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=123,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=123,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_ds = val_ds.take(5)\n",
    "    val_ds = val_ds.skip(5)\n",
    "\n",
    "    normalization_layer = layers.Rescaling(1./255)\n",
    "    train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "def create_advanced_model(num_classes=3):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    for layer in base_model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def advanced_augmentation(image, label):\n",
    "    image = tf.cast(image, tf.float32)  # Ensure image is float32\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_hue(image, max_delta=0.2)\n",
    "    return image, label\n",
    "\n",
    "def mixup(image, label, alpha=0.2):\n",
    "    batch_size = tf.shape(image)[0]\n",
    "    lam = tf.random.uniform(shape=(), minval=0, maxval=alpha)\n",
    "    index = tf.random.shuffle(tf.range(batch_size))\n",
    "    mixed_image = lam * image + (1 - lam) * tf.gather(image, index)\n",
    "    mixed_label = lam * label + (1 - lam) * tf.gather(label, index)\n",
    "    return mixed_image, mixed_label\n",
    "\n",
    "def custom_schedule(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return float(lr)\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))\n",
    "\n",
    "def train_and_evaluate_model(model, train_ds, val_ds, test_ds, class_weights, epochs=50):\n",
    "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(custom_schedule)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=5),\n",
    "        lr_schedule\n",
    "    ]\n",
    "    \n",
    "    # Apply advanced augmentation and mixup\n",
    "    train_ds = train_ds.map(advanced_augmentation)\n",
    "    train_ds = train_ds.map(lambda x, y: mixup(x, tf.one_hot(tf.cast(y, tf.int32), depth=3)))\n",
    "    \n",
    "    val_ds = val_ds.map(lambda x, y: (x, tf.one_hot(tf.cast(y, tf.int32), depth=3)))\n",
    "    test_ds = test_ds.map(lambda x, y: (x, tf.one_hot(tf.cast(y, tf.int32), depth=3)))\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds, \n",
    "        validation_data=val_ds, \n",
    "        epochs=epochs, \n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return history, test_acc\n",
    "\n",
    "# Main execution\n",
    "data_dir = r\"C:/Users/91911/OneDrive/Desktop/IEEE/COFFEE/dataset\"\n",
    "train_ds, val_ds, test_ds = load_and_preprocess_data(data_dir)\n",
    "\n",
    "# Calculate class weights\n",
    "y_train = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Create and train the advanced model\n",
    "advanced_model = create_advanced_model()\n",
    "print(\"\\nTraining advanced model:\")\n",
    "history, advanced_acc = train_and_evaluate_model(advanced_model, train_ds, val_ds, test_ds, class_weights)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nAdvanced Model Accuracy: {advanced_acc:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "advanced_model.save('best_coffee_leaf_model.h5')\n",
    "print(f\"\\nBest model saved as 'best_coffee_leaf_model.h5'\")\n",
    "print(f\"Training history plot saved as 'training_history.png'\")\n",
    "\n",
    "# Analyze misclassifications\n",
    "test_images = np.concatenate([x for x, _ in test_ds], axis=0)\n",
    "test_labels = np.concatenate([y for _, y in test_ds], axis=0)\n",
    "predictions = advanced_model.predict(test_images)\n",
    "misclassified = np.where(np.argmax(predictions, axis=1) != np.argmax(test_labels, axis=1))[0]\n",
    "\n",
    "print(f\"\\nNumber of misclassified images: {len(misclassified)}\")\n",
    "print(\"Class distribution of misclassified images:\")\n",
    "class_names = ['healthy', 'red_spider_mite', 'Rust']\n",
    "for class_idx, class_name in enumerate(class_names):\n",
    "    count = np.sum(np.argmax(test_labels[misclassified], axis=1) == class_idx)\n",
    "    print(f\"{class_name}: {count}\")\n",
    "\n",
    "# Save some misclassified images for further analysis\n",
    "num_images = min(5, len(misclassified))\n",
    "for i in range(num_images):\n",
    "    idx = misclassified[i]\n",
    "    plt.imshow(test_images[idx])\n",
    "    plt.title(f\"True: {class_names[np.argmax(test_labels[idx])]}, Predicted: {class_names[np.argmax(predictions[idx])]}\")\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'misclassified_{i}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"\\nSaved {num_images} misclassified images for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model saved as 'best_coffee_leaf_model.keras'\n"
     ]
    }
   ],
   "source": [
    "# Save using the new Keras format\n",
    "advanced_model.save('ragha_coffee_leaf_model.keras')\n",
    "print(\"\\nBest model saved as 'best_coffee_leaf_model.keras'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 2 classes.\n",
      "Using 800 files for training.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Using 200 files for validation.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>,\n      dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 107\u001b[0m\n\u001b[0;32m    104\u001b[0m kf \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m    105\u001b[0m fold_accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_index, val_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(train_ds)):\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Create and train the advanced model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:367\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m        The testing set indices for that split.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:454\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    >>> check_consistent_length(a, b)\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 454\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    455\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:382\u001b[0m, in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 382\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    383\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleton array \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cannot be considered a valid collection.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m x\n\u001b[0;32m    384\u001b[0m         )\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array(<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>,\n      dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 2 classes.\n",
      "Using 700 files for training.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Using 300 files for validation.\n",
      "\n",
      "Training fold 1\n",
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - accuracy: 0.4765 - loss: 6.9716 - val_accuracy: 0.6641 - val_loss: 6.6599 - learning_rate: 2.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 0.5691 - loss: 6.5241 - val_accuracy: 0.6484 - val_loss: 6.1686 - learning_rate: 4.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - accuracy: 0.5087 - loss: 5.9411 - val_accuracy: 0.5312 - val_loss: 5.3841 - learning_rate: 6.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.5871 - loss: 5.2090 - val_accuracy: 0.6172 - val_loss: 4.6322 - learning_rate: 8.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.5538 - loss: 4.3731 - val_accuracy: 0.5781 - val_loss: 3.7386 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.5698 - loss: 3.5822 - val_accuracy: 0.6328 - val_loss: 3.0352 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.6114 - loss: 2.9209 - val_accuracy: 0.4766 - val_loss: 2.6052 - learning_rate: 9.9973e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.5225 - loss: 2.5173 - val_accuracy: 0.3359 - val_loss: 2.2410 - learning_rate: 9.9891e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3s/step - accuracy: 0.6224 - loss: 2.0955 - val_accuracy: 0.6953 - val_loss: 1.7756 - learning_rate: 9.9754e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.6568 - loss: 1.7935 - val_accuracy: 0.7422 - val_loss: 1.6165 - learning_rate: 9.9563e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.6175 - loss: 1.5910 - val_accuracy: 0.4766 - val_loss: 1.4353 - learning_rate: 9.9318e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.5982 - loss: 1.4086 - val_accuracy: 0.6875 - val_loss: 1.3190 - learning_rate: 9.9019e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.6071 - loss: 1.2891 - val_accuracy: 0.6797 - val_loss: 1.1448 - learning_rate: 9.8666e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.5808 - loss: 1.1537 - val_accuracy: 0.6797 - val_loss: 1.0234 - learning_rate: 9.8260e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.7180 - loss: 1.0709 - val_accuracy: 0.6562 - val_loss: 1.0003 - learning_rate: 9.7802e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.6031 - loss: 1.0130 - val_accuracy: 0.7500 - val_loss: 0.9431 - learning_rate: 9.7291e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.6619 - loss: 0.9230 - val_accuracy: 0.6719 - val_loss: 0.8865 - learning_rate: 9.6728e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.6794 - loss: 0.8998 - val_accuracy: 0.7031 - val_loss: 0.7986 - learning_rate: 9.6114e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.6908 - loss: 0.8751 - val_accuracy: 0.6406 - val_loss: 0.8577 - learning_rate: 9.5450e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.6351 - loss: 0.8652 - val_accuracy: 0.7344 - val_loss: 0.7953 - learning_rate: 9.4736e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3s/step - accuracy: 0.7094 - loss: 0.8022 - val_accuracy: 0.6953 - val_loss: 0.7651 - learning_rate: 9.3974e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.6798 - loss: 0.8006 - val_accuracy: 0.6406 - val_loss: 0.7812 - learning_rate: 9.3163e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.6382 - loss: 0.8373 - val_accuracy: 0.6797 - val_loss: 0.7025 - learning_rate: 9.2305e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.5944 - loss: 0.8353 - val_accuracy: 0.6328 - val_loss: 0.7492 - learning_rate: 9.1400e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.6513 - loss: 0.7463 - val_accuracy: 0.3438 - val_loss: 0.9617 - learning_rate: 9.0451e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3s/step - accuracy: 0.6555 - loss: 0.7540 - val_accuracy: 0.7188 - val_loss: 0.6874 - learning_rate: 8.9457e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.6603 - loss: 0.7776 - val_accuracy: 0.6953 - val_loss: 0.7112 - learning_rate: 8.8420e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.6437 - loss: 0.7744 - val_accuracy: 0.6484 - val_loss: 0.7482 - learning_rate: 8.7341e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 0.7249 - loss: 0.7067 - val_accuracy: 0.6953 - val_loss: 0.6662 - learning_rate: 8.6221e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.6379 - loss: 0.8061 - val_accuracy: 0.6328 - val_loss: 0.7108 - learning_rate: 8.5062e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.7490 - loss: 0.6856 - val_accuracy: 0.7812 - val_loss: 0.6312 - learning_rate: 8.3864e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.6639 - loss: 0.7196 - val_accuracy: 0.6172 - val_loss: 0.7360 - learning_rate: 8.2629e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.7415 - loss: 0.6752 - val_accuracy: 0.7266 - val_loss: 0.6340 - learning_rate: 8.1359e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.6972 - loss: 0.6830 - val_accuracy: 0.7500 - val_loss: 0.6594 - learning_rate: 8.0054e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.7335 - loss: 0.6818 - val_accuracy: 0.3906 - val_loss: 0.7594 - learning_rate: 7.8716e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.7797 - loss: 0.7002 - val_accuracy: 0.3359 - val_loss: 0.7698 - learning_rate: 7.7347e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - accuracy: 0.6637 - loss: 0.6839 - val_accuracy: 0.3594 - val_loss: 0.7684 - learning_rate: 7.5948e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 0.7724 - loss: 0.6550 - val_accuracy: 0.6562 - val_loss: 0.6484 - learning_rate: 7.4521e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - accuracy: 0.7129 - loss: 0.6839 - val_accuracy: 0.7031 - val_loss: 0.6051 - learning_rate: 7.3067e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 4s/step - accuracy: 0.6903 - loss: 0.6910 - val_accuracy: 0.6562 - val_loss: 0.6740 - learning_rate: 7.1588e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.6483 - loss: 0.7028 - val_accuracy: 0.7969 - val_loss: 0.5909 - learning_rate: 7.0085e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.6907 - loss: 0.6937 - val_accuracy: 0.3672 - val_loss: 0.8809 - learning_rate: 6.8560e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.6583 - loss: 0.7255 - val_accuracy: 0.6953 - val_loss: 0.6600 - learning_rate: 6.7015e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.6713 - loss: 0.7552 - val_accuracy: 0.8047 - val_loss: 0.5971 - learning_rate: 6.5451e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.6725 - loss: 0.6750 - val_accuracy: 0.6094 - val_loss: 0.6991 - learning_rate: 6.3870e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - accuracy: 0.7415 - loss: 0.6536 - val_accuracy: 0.6328 - val_loss: 0.6859 - learning_rate: 6.2274e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.6901 - loss: 0.6843 - val_accuracy: 0.7969 - val_loss: 0.5463 - learning_rate: 6.0665e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 0.6696 - loss: 0.6971 - val_accuracy: 0.7422 - val_loss: 0.6621 - learning_rate: 5.9044e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 3s/step - accuracy: 0.7911 - loss: 0.6205 - val_accuracy: 0.6328 - val_loss: 0.6564 - learning_rate: 5.7413e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.6605 - loss: 0.7193 - val_accuracy: 0.7578 - val_loss: 0.6435 - learning_rate: 5.5774e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.7241 - loss: 0.6512 - val_accuracy: 0.4141 - val_loss: 0.7724 - learning_rate: 5.4129e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 3s/step - accuracy: 0.7293 - loss: 0.6623 - val_accuracy: 0.5234 - val_loss: 0.7029 - learning_rate: 5.2479e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.7289 - loss: 0.6585 - val_accuracy: 0.3594 - val_loss: 0.7587 - learning_rate: 5.0827e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.6866 - loss: 0.7011 - val_accuracy: 0.7812 - val_loss: 0.6068 - learning_rate: 4.9173e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 0.6711 - loss: 0.6841 - val_accuracy: 0.8203 - val_loss: 0.5881 - learning_rate: 4.7521e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.7174 - loss: 0.6878 - val_accuracy: 0.8438 - val_loss: 0.5913 - learning_rate: 4.5871e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 3s/step - accuracy: 0.7646 - loss: 0.6202 - val_accuracy: 0.7734 - val_loss: 0.5243 - learning_rate: 4.4226e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.6571 - loss: 0.6634 - val_accuracy: 0.6328 - val_loss: 0.6572 - learning_rate: 4.2587e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.7414 - loss: 0.6829 - val_accuracy: 0.8125 - val_loss: 0.5549 - learning_rate: 4.0956e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - accuracy: 0.6859 - loss: 0.6983 - val_accuracy: 0.7109 - val_loss: 0.6252 - learning_rate: 3.9335e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.6988 - loss: 0.6891 - val_accuracy: 0.6016 - val_loss: 0.6831 - learning_rate: 3.7726e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - accuracy: 0.7745 - loss: 0.6240 - val_accuracy: 0.6797 - val_loss: 0.6551 - learning_rate: 3.6130e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3s/step - accuracy: 0.7856 - loss: 0.5783 - val_accuracy: 0.8047 - val_loss: 0.5375 - learning_rate: 3.4549e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.7248 - loss: 0.5896 - val_accuracy: 0.7266 - val_loss: 0.5994 - learning_rate: 3.2985e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.6405 - loss: 0.6777 - val_accuracy: 0.9062 - val_loss: 0.4865 - learning_rate: 3.1440e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.6861 - loss: 0.6371 - val_accuracy: 0.8828 - val_loss: 0.4382 - learning_rate: 2.9915e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.6873 - loss: 0.7016 - val_accuracy: 0.7031 - val_loss: 0.6265 - learning_rate: 2.8412e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - accuracy: 0.7053 - loss: 0.6118 - val_accuracy: 0.6797 - val_loss: 0.6227 - learning_rate: 2.6933e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.7555 - loss: 0.6142 - val_accuracy: 0.9141 - val_loss: 0.5145 - learning_rate: 2.5479e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.7536 - loss: 0.6261 - val_accuracy: 0.9219 - val_loss: 0.4513 - learning_rate: 2.4052e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.7416 - loss: 0.6296 - val_accuracy: 0.7188 - val_loss: 0.5723 - learning_rate: 2.2653e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.7552 - loss: 0.6396 - val_accuracy: 0.8984 - val_loss: 0.4572 - learning_rate: 2.1284e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.7276 - loss: 0.6397 - val_accuracy: 0.7734 - val_loss: 0.5796 - learning_rate: 1.9946e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.7051 - loss: 0.6751 - val_accuracy: 0.8203 - val_loss: 0.5123 - learning_rate: 1.8641e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 3s/step - accuracy: 0.6783 - loss: 0.6871 - val_accuracy: 0.9141 - val_loss: 0.4488 - learning_rate: 1.7371e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.7377 - loss: 0.6001 - val_accuracy: 0.9375 - val_loss: 0.4484 - learning_rate: 1.6136e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.7308 - loss: 0.6518 - val_accuracy: 0.8984 - val_loss: 0.4988 - learning_rate: 1.4938e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.7200 - loss: 0.6402 - val_accuracy: 0.9609 - val_loss: 0.4300 - learning_rate: 1.3779e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.7679 - loss: 0.5748 - val_accuracy: 0.8281 - val_loss: 0.5224 - learning_rate: 1.2659e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8038 - loss: 0.5712 - val_accuracy: 0.6562 - val_loss: 0.6347 - learning_rate: 1.1580e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.6453 - loss: 0.6485 - val_accuracy: 0.9766 - val_loss: 0.3761 - learning_rate: 1.0543e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.8019 - loss: 0.6255 - val_accuracy: 0.9766 - val_loss: 0.3762 - learning_rate: 9.5492e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - accuracy: 0.6742 - loss: 0.6689 - val_accuracy: 0.9688 - val_loss: 0.4020 - learning_rate: 8.5996e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 3s/step - accuracy: 0.6826 - loss: 0.6467 - val_accuracy: 0.7969 - val_loss: 0.5337 - learning_rate: 7.6952e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.7341 - loss: 0.6452 - val_accuracy: 0.9375 - val_loss: 0.4352 - learning_rate: 6.8372e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.7117 - loss: 0.6362 - val_accuracy: 0.9688 - val_loss: 0.3816 - learning_rate: 6.0263e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.6714 - loss: 0.6829 - val_accuracy: 0.9844 - val_loss: 0.3939 - learning_rate: 5.2635e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.7240 - loss: 0.5911 - val_accuracy: 0.9688 - val_loss: 0.3736 - learning_rate: 4.5497e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.7632 - loss: 0.6211 - val_accuracy: 0.9844 - val_loss: 0.3721 - learning_rate: 3.8855e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.8878 - loss: 0.5622 - val_accuracy: 0.9688 - val_loss: 0.3642 - learning_rate: 3.2718e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - accuracy: 0.8162 - loss: 0.5999 - val_accuracy: 0.9766 - val_loss: 0.3518 - learning_rate: 2.7091e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.8421 - loss: 0.5956 - val_accuracy: 0.9922 - val_loss: 0.3395 - learning_rate: 2.1982e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.6978 - loss: 0.5931 - val_accuracy: 0.9922 - val_loss: 0.3386 - learning_rate: 1.7396e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - accuracy: 0.8064 - loss: 0.5911 - val_accuracy: 0.9922 - val_loss: 0.3349 - learning_rate: 1.3337e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.7400 - loss: 0.6636 - val_accuracy: 1.0000 - val_loss: 0.3450 - learning_rate: 9.8100e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.6642 - loss: 0.6473 - val_accuracy: 0.9844 - val_loss: 0.3465 - learning_rate: 6.8193e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - accuracy: 0.7537 - loss: 0.5901 - val_accuracy: 0.9844 - val_loss: 0.3400 - learning_rate: 4.3680e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - accuracy: 0.8435 - loss: 0.5644 - val_accuracy: 0.9922 - val_loss: 0.3440 - learning_rate: 2.4585e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 0.8331 - loss: 0.5757 - val_accuracy: 0.9844 - val_loss: 0.3546 - learning_rate: 1.0932e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.7787 - loss: 0.6478 - val_accuracy: 0.9844 - val_loss: 0.3462 - learning_rate: 2.7337e-07\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.8700 - loss: 0.4778\n",
      "Test accuracy: 0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to synchronously create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 172\u001b[0m\n\u001b[0;32m    169\u001b[0m     fold_accuracies\u001b[38;5;241m.\u001b[39mappend(fold_acc)\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# Save the model for this fold\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m     \u001b[43madvanced_model_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoffee_leaf_model_fold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Print cross-validation results\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCross-validation results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\h5py\\_hl\\group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32mc:\\Users\\91911\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\h5py\\_hl\\dataset.py:163\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[1;32m--> 163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m    166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5d.pyx:137\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to synchronously create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "def create_advanced_model_v2(num_classes=3):\n",
    "    base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    for layer in base_model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dropout(0.6)(x)\n",
    "    x = layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dropout(0.6)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def tf_random_beta(alpha, beta, shape=[]):\n",
    "    x = tf.random.gamma(shape, alpha, 1.0)\n",
    "    y = tf.random.gamma(shape, beta, 1.0)\n",
    "    return x / (x + y)\n",
    "\n",
    "def cutmix(image, label, alpha=1.0):\n",
    "    batch_size = tf.shape(image)[0]\n",
    "    image_size = tf.shape(image)[1]\n",
    "    \n",
    "    # Generate random bounding box\n",
    "    lambda_ = tf_random_beta(alpha, alpha, shape=[])\n",
    "    r_x = tf.random.uniform(shape=[], minval=0, maxval=image_size, dtype=tf.int32)\n",
    "    r_y = tf.random.uniform(shape=[], minval=0, maxval=image_size, dtype=tf.int32)\n",
    "    r_w = tf.cast(tf.cast(image_size, tf.float32) * tf.sqrt(1 - lambda_), tf.int32)\n",
    "    r_h = tf.cast(tf.cast(image_size, tf.float32) * tf.sqrt(1 - lambda_), tf.int32)\n",
    "    \n",
    "    # Adjust bounding box to be within image\n",
    "    x1 = tf.clip_by_value(r_x - r_w // 2, 0, image_size)\n",
    "    y1 = tf.clip_by_value(r_y - r_h // 2, 0, image_size)\n",
    "    x2 = tf.clip_by_value(r_x + r_w // 2, 0, image_size)\n",
    "    y2 = tf.clip_by_value(r_y + r_h // 2, 0, image_size)\n",
    "    \n",
    "    # Create mask\n",
    "    mask = tf.pad(tf.ones((y2-y1, x2-x1)), [[y1, image_size-y2], [x1, image_size-x2]])\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    # Apply CutMix\n",
    "    image2 = tf.random.shuffle(image)\n",
    "    label2 = tf.random.shuffle(label)\n",
    "    mixed_image = image * (1 - mask) + image2 * mask\n",
    "    mixed_label = label * (1 - lambda_) + label2 * lambda_\n",
    "    \n",
    "    return mixed_image, mixed_label\n",
    "\n",
    "# def cosine_annealing_warmup(epoch, lr, total_epochs, warmup_epochs=5):\n",
    "#     if epoch < warmup_epochs:\n",
    "#         return lr * (epoch + 1) / warmup_epochs\n",
    "#     else:\n",
    "#         return lr * 0.5 * (1 + tf.math.cos(tf.constant(np.pi) * (epoch - warmup_epochs) / (total_epochs - warmup_epochs)))\n",
    "    \n",
    "def cosine_annealing_warmup(epoch, lr, total_epochs, warmup_epochs=5):\n",
    "    if epoch < warmup_epochs:\n",
    "        return lr * (epoch + 1) / warmup_epochs\n",
    "    else:\n",
    "        return lr * 0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs) / (total_epochs - warmup_epochs)))\n",
    "\n",
    "# Modify the LearningRateScheduler to use this updated function\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: float(cosine_annealing_warmup(epoch, 1e-3, epochs)))\n",
    "\n",
    "\n",
    "def train_and_evaluate_model_v2(model, train_ds, val_ds, test_ds, class_weights, epochs=100):\n",
    "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: cosine_annealing_warmup(epoch, 1e-3, epochs))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True),\n",
    "        lr_schedule\n",
    "    ]\n",
    "    \n",
    "    # Apply CutMix\n",
    "    train_ds = train_ds.map(lambda x, y: cutmix(x, tf.one_hot(tf.cast(y, tf.int32), depth=3)))\n",
    "    \n",
    "    val_ds = val_ds.map(lambda x, y: (x, tf.one_hot(tf.cast(y, tf.int32), depth=3)))\n",
    "    test_ds = test_ds.map(lambda x, y: (x, tf.one_hot(tf.cast(y, tf.int32), depth=3)))\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds, \n",
    "        validation_data=val_ds, \n",
    "        epochs=epochs, \n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return history, test_acc\n",
    "\n",
    "def load_and_preprocess_data(data_dir, image_size=(224, 224), batch_size=32, val_split=0.2, test_split=0.1):\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='int',  # For integer labels\n",
    "        validation_split=val_split + test_split,  # Total validation + test split\n",
    "        subset='training',\n",
    "        seed=123\n",
    "    )\n",
    "\n",
    "    val_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='int',\n",
    "        validation_split=val_split + test_split,\n",
    "        subset='validation',\n",
    "        seed=123\n",
    "    )\n",
    "\n",
    "    # Split val_test_ds into val_ds and test_ds\n",
    "    val_size = int(val_split / (val_split + test_split) * tf.data.experimental.cardinality(val_test_ds).numpy())\n",
    "    val_ds = val_test_ds.take(val_size)\n",
    "    test_ds = val_test_ds.skip(val_size)\n",
    "\n",
    "    # Apply basic preprocessing\n",
    "    normalization_layer = layers.Rescaling(1./255)\n",
    "    train_ds = dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "    val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "# Main execution\n",
    "data_dir = r\"C:/Users/91911/OneDrive/Desktop/IEEE/COFFEE/dataset\"\n",
    "train_ds, val_ds, test_ds = load_and_preprocess_data(data_dir)\n",
    "\n",
    "# Calculate class weights\n",
    "y_train = np.concatenate([y.numpy() for x, y in train_ds], axis=0)\n",
    "class_weights = dict(enumerate(class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)))\n",
    "\n",
    "# Implement custom cross-validation\n",
    "n_folds = 5\n",
    "dataset_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "fold_size = dataset_size // n_folds\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    print(f\"\\nTraining fold {fold + 1}\")\n",
    "    \n",
    "    val_start = fold * fold_size\n",
    "    val_end = (fold + 1) * fold_size\n",
    "    \n",
    "    val_ds_fold = train_ds.skip(val_start).take(fold_size)\n",
    "    train_ds_fold = train_ds.take(val_start).concatenate(train_ds.skip(val_end))\n",
    "    \n",
    "    # Create and train the advanced model\n",
    "    advanced_model_v2 = create_advanced_model_v2()\n",
    "    history, fold_acc = train_and_evaluate_model_v2(advanced_model_v2, train_ds_fold, val_ds_fold, test_ds, class_weights)\n",
    "    fold_accuracies.append(fold_acc)\n",
    "\n",
    "    # Save the model for this fold\n",
    "    advanced_model_v2.save(f'coffee_leaf_model_fold_{fold+1}.h5')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"\\nCross-validation results:\")\n",
    "for i, acc in enumerate(fold_accuracies):\n",
    "    print(f\"Fold {i+1} accuracy: {acc:.4f}\")\n",
    "print(f\"Mean accuracy: {np.mean(fold_accuracies):.4f} (+/- {np.std(fold_accuracies):.4f})\")\n",
    "\n",
    "# Save the best model (highest accuracy)\n",
    "best_fold = np.argmax(fold_accuracies)\n",
    "best_model = tf.keras.models.load_model(f'coffee_leaf_model_fold_{best_fold+1}.h5')\n",
    "best_model.save('best_coffee_leaf_model_final.h5')\n",
    "\n",
    "print(f\"\\nBest model (from fold {best_fold+1}) saved as 'best_coffee_leaf_model_final.h5'\")\n",
    "\n",
    "# Analyze misclassifications using the best model\n",
    "test_images = np.concatenate([x.numpy() for x, _ in test_ds], axis=0)\n",
    "test_labels = np.concatenate([y.numpy() for _, y in test_ds], axis=0)\n",
    "predictions = best_model.predict(test_images)\n",
    "misclassified = np.where(np.argmax(predictions, axis=1) != np.argmax(test_labels, axis=1))[0]\n",
    "\n",
    "print(f\"\\nNumber of misclassified images: {len(misclassified)}\")\n",
    "print(\"Class distribution of misclassified images:\")\n",
    "class_names = ['healthy', 'red_spider_mite', 'Rust']\n",
    "for class_idx, class_name in enumerate(class_names):\n",
    "    count = np.sum(np.argmax(test_labels[misclassified], axis=1) == class_idx)\n",
    "    print(f\"{class_name}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'best_coffee_leaf_model_final.keras'\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is your trained model\n",
    "model.save('best_coffee_leaf_model_final.keras')\n",
    "print(\"Model saved as 'best_coffee_leaf_model_final.keras'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('learning_curves.png')\n",
    "    plt.close()\n",
    "\n",
    "# After training\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\91911\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\91911\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\91911\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\91911\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\91911\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\91911\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (1.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\91911\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91911\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug: * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91911\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\91911\\OneDrive\\Desktop\\IEEE\\COFFEE\n",
      "Files in this directory: ['bestleaf_model2.h5', 'best_coffee_leaf_model.h5', 'best_coffee_leaf_model2.h5', 'best_coffee_leaf_modelww.h5', 'best_coffee_leaf_model_1725653124.h5', 'best_coffee_leaf_model_v2.h5', 'cnn_coffee_leaf_model.h5', 'coffee.ipynb', 'coffeee.ipynb', 'coffee_leaf_model_fold_1.h5', 'dataset', 'learning_curves.png', 'ragha_coffee_leaf_model.keras', 'rag_coffee_leaf_model2.h5', 'training_history.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files in this directory:\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
